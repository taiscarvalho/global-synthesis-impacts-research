{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cassis import load_typesystem, load_cas_from_xmi\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the 'annotation 'subfolder of the unzipped export file\n",
    "anndir = \"data/annotated-papers\"\n",
    "\n",
    "# The folder contains subfolders for all documents in inception \n",
    "# We loop over these subfolders\n",
    "for docdir in os.listdir(anndir):\n",
    "\n",
    "    fulldocdir = os.path.join(anndir,docdir)\n",
    "    \n",
    "    if zipfile.is_zipfile(fulldocdir):\n",
    "        print(fulldocdir)\n",
    "        z = zipfile.ZipFile(fulldocdir)\n",
    "        l = z.namelist()\n",
    "        print(l)\n",
    "        ts = load_typesystem(z.open('TypeSystem.xml').read().decode())\n",
    "        xmi = l[0] if l[0] != 'TypeSystem.xml' else l[1]   # get name of other file in zipfile\n",
    "        annotator = xmi.split('.')[0]                      # annotator name derived from filename\n",
    "        cas = load_cas_from_xmi(z.open(xmi).read().decode(), typesystem=ts)\n",
    "\n",
    "        with open(\"data/annotated-papers/output/output_\" + docdir, 'w') as f:\n",
    "            for segment in cas.select('custom.SentenceLabel'):\n",
    "                f.write(f\"{segment.get_covered_text()}\\t{segment.label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs = []\n",
    "\n",
    "for docdir in os.listdir(anndir):\n",
    "    fulldocdir = os.path.join(anndir, docdir)\n",
    "    if zipfile.is_zipfile(fulldocdir):\n",
    "        # Create empty lists to store data\n",
    "        sentences = []\n",
    "        classes = []\n",
    "\n",
    "        # Read the text file line by line\n",
    "        with open(\"data/annotated-papers/output/output_\" + docdir, 'r', errors='replace') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Process each line and extract sentences and classes\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) == 2:\n",
    "                    sentence, class_label = parts\n",
    "                    sentences.append(sentence)\n",
    "                    classes.append(class_label)\n",
    "\n",
    "        # Create a pandas DataFrame\n",
    "        df = pd.DataFrame({\"title_cod\": docdir[15:-4], \"text\": sentences, \"labels\": classes})\n",
    "\n",
    "        list_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(list_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results/df_labelled_sentences.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
